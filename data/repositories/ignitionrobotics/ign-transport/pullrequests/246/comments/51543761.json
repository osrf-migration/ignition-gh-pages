{"links": {"self": {"href": "data/repositories/ignitionrobotics/ign-transport/pullrequests/246/comments/51543761.json"}, "code": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-transport/diff/ignitionrobotics/ign-transport:25a1f194b6c5..43d06abac763?path=tools%2Frecord%2Fsrc%2Frecord.cpp"}, "html": {"href": "#!/ignitionrobotics/ign-transport/pull-requests/246/_/diff#comment-51543761"}}, "deleted": false, "pullrequest": {"type": "pullrequest", "id": 246, "links": {"self": {"href": "data/repositories/ignitionrobotics/ign-transport/pullrequests/246.json"}, "html": {"href": "#!/ignitionrobotics/ign-transport/pull-requests/246"}}, "title": "Record proof of concept (do not merge)"}, "content": {"raw": "Is there any way of deferring the load of the file to sqlite3? It might be overkill to read the entire file at once when the file is big.", "markup": "markdown", "html": "<p>Is there any way of deferring the load of the file to sqlite3? It might be overkill to read the entire file at once when the file is big.</p>", "type": "rendered"}, "created_on": "2017-12-09T17:28:19.077137+00:00", "user": {"display_name": "Carlos Ag\u00fcero", "uuid": "{da8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D"}, "html": {"href": "https://bitbucket.org/%7Bda8a8e89-4bb0-421b-bd0e-dbbed3d4ed6a%7D/"}, "avatar": {"href": "data/secure.gravatar.com/avatar/692bf15758111acaddae4da15a47f9e5d=httpsavatar-management--avatars.us-west-2.prod.public.atl-paas.netinitialsCA-0.png"}}, "nickname": "caguero", "type": "user", "account_id": "557058:4ded1ddf-947e-4154-bbd1-3dba24f1bdbd"}, "inline": {"to": 64, "from": null, "outdated": true, "path": "tools/record/src/record.cpp"}, "updated_on": "2017-12-09T17:28:19.079488+00:00", "type": "pullrequest_comment", "id": 51543761}