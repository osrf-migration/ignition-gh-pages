{"rendered": {"description": {"raw": "Added ogre2 implementation of gpu rays.\r\n\r\nSimilar to the 2 pass approach in the ogre1.x, the idea is to get depth data in the 1st pass and compute the correct range value for each ray in the sensor in the 2nd pass. The implementation is quite different. In the ogre2 implementation, we use 2 compositor workspaces for rendering to texture, i.e. one for each pass. The 1st pass creates a cubemap of depth data \\(more specifically they are converted to viewspace \u2018range\u2019 values\\), and the 2nd pass samples these range values from the cubemap using rays.\r\n\r\nNote that the downside of sampling from depth buffer is [precision](https://www.khronos.org/opengl/wiki/Depth_Buffer_Precision), which is affected by the near/far clip planes \\(min/max range settings\\). So objects far away \\(close to far clip plane\\) may suffer from less accurate readings.\r\n\r\nTo run ogre2 tests from build directory:\r\n\r\n`RENDER_ENGINE_VALUES=ogre2 make test`", "markup": "markdown", "html": "<p>Added ogre2 implementation of gpu rays.</p>\n<p>Similar to the 2 pass approach in the ogre1.x, the idea is to get depth data in the 1st pass and compute the correct range value for each ray in the sensor in the 2nd pass. The implementation is quite different. In the ogre2 implementation, we use 2 compositor workspaces for rendering to texture, i.e. one for each pass. The 1st pass creates a cubemap of depth data (more specifically they are converted to viewspace \u2018range\u2019 values), and the 2nd pass samples these range values from the cubemap using rays.</p>\n<p>Note that the downside of sampling from depth buffer is <a data-is-external-link=\"true\" href=\"https://www.khronos.org/opengl/wiki/Depth_Buffer_Precision\" rel=\"nofollow\">precision</a>, which is affected by the near/far clip planes (min/max range settings). So objects far away (close to far clip plane) may suffer from less accurate readings.</p>\n<p>To run ogre2 tests from build directory:</p>\n<p><code>RENDER_ENGINE_VALUES=ogre2 make test</code></p>", "type": "rendered"}, "title": {"raw": "Add Ogre2GpuRays sensor", "markup": "markdown", "html": "<p>Add Ogre2GpuRays sensor</p>", "type": "rendered"}}, "type": "pullrequest", "description": "Added ogre2 implementation of gpu rays.\r\n\r\nSimilar to the 2 pass approach in the ogre1.x, the idea is to get depth data in the 1st pass and compute the correct range value for each ray in the sensor in the 2nd pass. The implementation is quite different. In the ogre2 implementation, we use 2 compositor workspaces for rendering to texture, i.e. one for each pass. The 1st pass creates a cubemap of depth data \\(more specifically they are converted to viewspace \u2018range\u2019 values\\), and the 2nd pass samples these range values from the cubemap using rays.\r\n\r\nNote that the downside of sampling from depth buffer is [precision](https://www.khronos.org/opengl/wiki/Depth_Buffer_Precision), which is affected by the near/far clip planes \\(min/max range settings\\). So objects far away \\(close to far clip plane\\) may suffer from less accurate readings.\r\n\r\nTo run ogre2 tests from build directory:\r\n\r\n`RENDER_ENGINE_VALUES=ogre2 make test`", "links": {"decline": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-rendering/pullrequests/128/decline"}, "diffstat": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-rendering/diffstat/ignitionrobotics/ign-rendering:2e2d86ddcada%0Dd9855029cb5f?from_pullrequest_id=128"}, "commits": {"href": "data/repositories/ignitionrobotics/ign-rendering/pullrequests/128/commits.json"}, "self": {"href": "data/repositories/ignitionrobotics/ign-rendering/pullrequests/128.json"}, "comments": {"href": "data/repositories/ignitionrobotics/ign-rendering/pullrequests/128/comments_page=1.json"}, "merge": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-rendering/pullrequests/128/merge"}, "html": {"href": "#!/ignitionrobotics/ign-rendering/pull-requests/128"}, "activity": {"href": "data/repositories/ignitionrobotics/ign-rendering/pullrequests/128/activity.json"}, "diff": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-rendering/diff/ignitionrobotics/ign-rendering:2e2d86ddcada%0Dd9855029cb5f?from_pullrequest_id=128"}, "approve": {"href": "https://api.bitbucket.org/2.0/repositories/ignitionrobotics/ign-rendering/pullrequests/128/approve"}, "statuses": {"href": "data/repositories/ignitionrobotics/ign-rendering/pullrequests/128/statuses_page=1.json"}}, "title": "Add Ogre2GpuRays sensor", "close_source_branch": true, "reviewers": [], "id": 128, "destination": {"commit": {"hash": "d9855029cb5f", "type": "commit", "links": {"self": {"href": "data/repositories/ignitionrobotics/ign-rendering/commit/d9855029cb5f.json"}, "html": {"href": "#!/ignitionrobotics/ign-rendering/commits/d9855029cb5f"}}}, "repository": {"links": {"self": {"href": "data/repositories/ignitionrobotics/ign-rendering.json"}, "html": {"href": "#!/ignitionrobotics/ign-rendering"}, "avatar": {"href": "data/bytebucket.org/ravatar/{f6b404b6-f373-460d-a470-69ff6f27cd93}ts=1533308"}}, "type": "repository", "name": "ign-rendering", "full_name": "ignitionrobotics/ign-rendering", "uuid": "{f6b404b6-f373-460d-a470-69ff6f27cd93}"}, "branch": {"name": "gz11"}}, "created_on": "2018-12-21T19:00:07.878035+00:00", "summary": {"raw": "Added ogre2 implementation of gpu rays.\r\n\r\nSimilar to the 2 pass approach in the ogre1.x, the idea is to get depth data in the 1st pass and compute the correct range value for each ray in the sensor in the 2nd pass. The implementation is quite different. In the ogre2 implementation, we use 2 compositor workspaces for rendering to texture, i.e. one for each pass. The 1st pass creates a cubemap of depth data \\(more specifically they are converted to viewspace \u2018range\u2019 values\\), and the 2nd pass samples these range values from the cubemap using rays.\r\n\r\nNote that the downside of sampling from depth buffer is [precision](https://www.khronos.org/opengl/wiki/Depth_Buffer_Precision), which is affected by the near/far clip planes \\(min/max range settings\\). So objects far away \\(close to far clip plane\\) may suffer from less accurate readings.\r\n\r\nTo run ogre2 tests from build directory:\r\n\r\n`RENDER_ENGINE_VALUES=ogre2 make test`", "markup": "markdown", "html": "<p>Added ogre2 implementation of gpu rays.</p>\n<p>Similar to the 2 pass approach in the ogre1.x, the idea is to get depth data in the 1st pass and compute the correct range value for each ray in the sensor in the 2nd pass. The implementation is quite different. In the ogre2 implementation, we use 2 compositor workspaces for rendering to texture, i.e. one for each pass. The 1st pass creates a cubemap of depth data (more specifically they are converted to viewspace \u2018range\u2019 values), and the 2nd pass samples these range values from the cubemap using rays.</p>\n<p>Note that the downside of sampling from depth buffer is <a data-is-external-link=\"true\" href=\"https://www.khronos.org/opengl/wiki/Depth_Buffer_Precision\" rel=\"nofollow\">precision</a>, which is affected by the near/far clip planes (min/max range settings). So objects far away (close to far clip plane) may suffer from less accurate readings.</p>\n<p>To run ogre2 tests from build directory:</p>\n<p><code>RENDER_ENGINE_VALUES=ogre2 make test</code></p>", "type": "rendered"}, "source": {"commit": {"hash": "cfad341ffdb0", "type": "commit", "links": {"self": {"href": "data/repositories/ignitionrobotics/ign-rendering/commit/cfad341ffdb0.json"}, "html": {"href": "#!/ignitionrobotics/ign-rendering/commits/cfad341ffdb0"}}}, "repository": {"links": {"self": {"href": "data/repositories/ignitionrobotics/ign-rendering.json"}, "html": {"href": "#!/ignitionrobotics/ign-rendering"}, "avatar": {"href": "data/bytebucket.org/ravatar/{f6b404b6-f373-460d-a470-69ff6f27cd93}ts=1533308"}}, "type": "repository", "name": "ign-rendering", "full_name": "ignitionrobotics/ign-rendering", "uuid": "{f6b404b6-f373-460d-a470-69ff6f27cd93}"}, "branch": {"name": "ogre2_gpulaser_multicam"}}, "comment_count": 4, "state": "MERGED", "task_count": 0, "participants": [{"role": "PARTICIPANT", "participated_on": "2018-12-27T22:36:12.828947+00:00", "type": "participant", "approved": true, "user": {"display_name": "Javier Iv\u00e1n Choclin", "uuid": "{745acb37-6a3b-4169-8ba9-2c142a7408fb}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7B745acb37-6a3b-4169-8ba9-2c142a7408fb%7D"}, "html": {"href": "https://bitbucket.org/%7B745acb37-6a3b-4169-8ba9-2c142a7408fb%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:2279399d-3c75-4e1e-b818-4fb8339b2939/26f5815d-5477-4106-ba9b-ac56ee23e175/128"}}, "nickname": "Javier Choclin", "type": "user", "account_id": "557058:2279399d-3c75-4e1e-b818-4fb8339b2939"}}, {"role": "PARTICIPANT", "participated_on": "2018-12-26T21:58:34.208395+00:00", "type": "participant", "approved": false, "user": {"display_name": "Ian Chen", "uuid": "{eaa6fca5-6deb-43f6-907f-971c144735dd}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D"}, "html": {"href": "https://bitbucket.org/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5/1e4adcdf-1946-4280-9aea-eb5f15a7f912/128"}}, "nickname": "Ian Chen", "type": "user", "account_id": "557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5"}}], "reason": "", "updated_on": "2018-12-27T22:54:55.569303+00:00", "author": {"display_name": "Ian Chen", "uuid": "{eaa6fca5-6deb-43f6-907f-971c144735dd}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D"}, "html": {"href": "https://bitbucket.org/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5/1e4adcdf-1946-4280-9aea-eb5f15a7f912/128"}}, "nickname": "Ian Chen", "type": "user", "account_id": "557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5"}, "merge_commit": {"hash": "2e2d86ddcada", "type": "commit", "links": {"self": {"href": "data/repositories/ignitionrobotics/ign-rendering/commit/2e2d86ddcada.json"}, "html": {"href": "#!/ignitionrobotics/ign-rendering/commits/2e2d86ddcada"}}}, "closed_by": {"display_name": "Ian Chen", "uuid": "{eaa6fca5-6deb-43f6-907f-971c144735dd}", "links": {"self": {"href": "https://api.bitbucket.org/2.0/users/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D"}, "html": {"href": "https://bitbucket.org/%7Beaa6fca5-6deb-43f6-907f-971c144735dd%7D/"}, "avatar": {"href": "https://avatar-management--avatars.us-west-2.prod.public.atl-paas.net/557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5/1e4adcdf-1946-4280-9aea-eb5f15a7f912/128"}}, "nickname": "Ian Chen", "type": "user", "account_id": "557058:10b01d41-a2e9-4a41-a907-e6e2f03b6cd5"}}